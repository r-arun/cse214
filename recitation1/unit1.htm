<!-- saved from url=(0022)http://internet.e-mail -->
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>CSE214 Recitation 1</title>
<style type="text/css">
pre {
background-color: #dddddd;
color: blue;
font-family: "courier";
left: 100;
}
.question{
background-color: #ffffff;
color: #33aa11;
font-family: "georgia";
}
body{
font-family: "times";
}
</style>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body bgcolor="#FFFFFF">

<h2 align="center"><img src="unit1_files/logo.gif" border="0" height="100" width="200">&nbsp; <font color="#800080"><br>
</font><font color="#800000" face="Arial">Rectitation 1</font></h2>

<hr>
<h4>Algorithm</h4>
<p>
An algorithm is a finite sequence of steps that a machine can execute. An algorithm generally takes an input and produces an output, and a machine can complete the execution of an algorithm in a finite time.
</p>
<p>Consider the problem of finding $x^y$. An algorithm for solving this problem is given below.
<ol>
<li>Take numbers $x$ and $y$.</li>
<li>Initialize $result = 1$.</li>
<li>Multiply the value of $result$ and $x$ and store it in $result$. Repeat the step $y$ times.</li>
<li>Output the value of $result$.</li>
</ol>
<pre><code class="java">
<code class = "keyword">int</code> exponent(<code class = "keyword">int</code> x, <code class = "keyword">int</code> y){
	<code class = "keyword">int</code> result = 1;
	<code class = "keyword">while</code>(y-- > 0){
		result = result * x;	
	}
	<code class = "keyword">return</code> result;
}
</code>
</pre>
</p>
<h4>Efficiency</h4>
<p>There can be several algorithms to solve the same problem. How can you compare different algorithms?</p>
<p>We can compare algorithms in terms of,
<ul>
<li>Time (running time)</li>
<li>Space (memory requirements)</li>
<li>Resources (disk I/O, cache, cost of hardware)</li>
<li>Accuracy (sometimes we accept approximate solutions)</li>
</ul></p>
<p>Let us focus on running time.</p>
<h4>Running Time</h4>
<p>
The simplest way to determine the running time, is to write a computer program representing the algorithm, run it on a computer and measure the time.  The faster an algorithm runs, the better. </p>
<p>But on different hardware, the same algorithms can have different running times.</p>
<p>We can compute the running time based on the number of instructions executed with respect to the size of the input. Consider the algorithm for finding the sum of first $n$ natural numbers.
<pre>

sum = 0
for i = 1 to n
	sum = sum + i
print sum

</pre>
Assume that the expression $sum = sum + i$ takes unit time to complete. How long
does the program for different values of $n$?
</p>
<ul>
<li>For $n =10$, the time taken is $10$.</li>
<li>For $n = 20$, the time taken is $20$.</li>
<li>For $n = 1000$, what is them time taken?</li>
</ul>
<p> In general we can say that for an input of size $n$, the time taken taken is also $n$.
</p>
<h4>Order of Complexity</h4>
<p>Count the number of "operations"</p>
<p>What is an "operation"?</p>
<p>Example:<br>
C = A + B;</p>
<p>1 operation?</p>
<p>4 operations?<br>
(LOAD A, LOAD B, ADD, STORE C)</p>
<!-- TODO Introduce All ordered pairs or cartesian product -->
<h4>All ordered pairs</h4>
<p>We look at another example. Given two arrays each of size $n$, find all ordered pairs of number.<br/>
For $A = \{1, 2, 3\}, B = \{4, 5\}$. The order pairs are $\{(1,4), (1,5), (2, 4), (2, 5), (3, 4), (3,5)\}$. The algorithm
is quite simple: Combine each element in $A$ with all elements of $B$ one at a time.</p>
<p>This is operation is also known as the cartesian product of $A$ and $B$. We used this example only to analyse
nested loops!</p>
<pre>

for(i = 0; i &lt; n; ++i){
	for(j = 0; j &lt; n; ++j){
		print (A[i], B[j])
	}
}

</pre>
<p> The outer loop executes $n$ times. Each time outer loop is executed, the inner loop (with $j$) executes $n$ times.
So the print statement is executed $n \times n$ times.</p>
<h4>How to analyze nested loops?</h4>
<p>In general, we consider all instructions except loops take constant time, (equivalent to 1 unit). Loops
take time equal to the number of times the loop is repeated. To compute the running time, consider each loop
(treated a nested loop as a single loop) and compute the running time for each iteration to get the running for
a single loop. Then, combine the times for each loop one by one.</p>
<pre>

for (x=1; x&lt;=n; x++)
	c = a + b;
for (x=1; x&lt;=n; x++)
{
	c = a + b;
	d = e + f;
}

</pre>
<p> The first loop has a running time of $n$. The second has $2$ instructions per iteration and the loop repeats
$n$ times.  In all, the second loop executes $2n$ instructions. Thus the total running time is $2n + n = 3n$.</p>
<h4>Big O Notation</h4>
<p>Given an algorithm/routine processing n inputs, what is the number of
operations as a function of $n$?</p>
<p>Big O expresses this function as a simplified function of n</p>
<p>$O(n)$ &#8211; a function of $n$</p>
<p>$O(n^2)$ &#8211; a function of $n^2$</p>

<p align="CENTER">Big O Notation (cont&#8217;d)</p>
<p>Let $f(n)$ and $g(n)$ be functions mapping nonnegative integers to real numbers.</p>
<p>We say that $f(n)$ is $O \left(g \left(n \right) \right)$ if there is a real constant $c > 0$ and an
integer constant $n_0 >  1$ such that $f(n) \lt cg(n)$
for every integer n <u>&gt;</u> n<sub>0</sub>.</p>
<p><img src="unit1_files/unit1_002.gif" border="0" height="146" width="409"><br>
</p>
<p>The last algorithm which had a running time of $3n$ is $O(n)$, if we choose a constant $c = 3.1$ (We can choose the constant!) or higher. Thus the running time is said to be $O(n)$ and linear in $n$.
<h4>Big O Examples</h4>
<pre>

for (x=1; x&lt;=n; x++)
	c = a + b;

</pre>
<p>The running time, $f(n) = O(n)$</p>
<pre>

for (x=1; x&lt;=n; x++)
{
	c = a + b;
	d = e + f;
}

</pre>
<p>The running time, $f(n) = O(2n) = O(n)$</p>
<h4>Big O Examples</h4>
<pre>

for (x=1; x&lt;=n; x++){
	c = a + b;
}
c = c + d;

</pre>
<p>The running time, $f(n) = O(n + 1) = O(n)$</p>
<pre>

for (x=1; x&lt;=n; x=x*2)
	c = a + b;

</pre>
<p>$O(\log_2 {n}) = O(\log n)$</p>
<pre>

for (x=1; x&lt;=n; x++) {
	d = e + f;
	for (y=n; y&gt;0; y--) {
		c = a + b;
		c = c * 2;
		d = c + d;
	}
}

</pre>
<p>This has nested loops. There is a simple technique for analysiing nested for loops. Consdier the inner most loop as a
single instruction, but with its original running time, ($3n$ in this case). Now compute the runnig time within the outer loop. It is $3n + 1$ and it is repeated $n$ times and hence $f(n) = 3n^2 +n = O(n^2).$ </p>
<p> There is definitely a constant $c > 0$ such that after, some size of input $n_0$,<br/>
$3n^2+ n < c n^2$.<br />
For example the constant can be $c = 3.3$ for $n_0 = 5$.
</p>
<p>You can also observe that $n^2 > n$, for large values of $n$ (like $n > 1). $n^2$ is said to grow faster than $n$, "asymptotically".</p>
<h3>General Trick: Fastest growing function dominates!</h3>
<p>Running time is a polynomial, written as a sum of many functions (like $n$, $n^2$, etc). Let $f_{fast}(n)$ be the fastest growing function in the polynomial. In that case, $f(n) = O(f_{fast}(n))$.</p>
<p>In the above example, the fastest growing function is $3n^2$. Hence $f(n) = O(n^2)$.
This is because, there always exists a constant $c > 0$ for which $f(n) < c \times f_{fast}(n)$  </p>


<h4>Worst-Case Running Time</h4>
Consider the algorithm for finding the number $42$ in an array of integers of size $n$.
<pre>

find(arr[]){
	arr is the array of integers
	for(i = 0 to n){
		if(arr[i] == 42)
			return true;
	}
	return false;
}

</pre>
<p>We can say that running time corresponds to number of array elements compared.</p>
<p>
Now consider the array $A = \{21, 31, 42, 52, 90, 85, 17\}$. $42$ is the $3^{rd}$ element in $A$ and so the
algorithm makes $3$ comparisons. So the running time $f(n) = 3$. If the elements of $A$ are rearranged, what is the
highest value $f(n)$ can take? If we move $42$ to the end of the array, we have to compare all elements of $A$, and <br/>
$f(n) = n = 7$.
</p>
<p class = "question">So if element $42$ is present only at the end of an array of size $n$, it forces the algorithm to perform all $n$
comparisons. There is also another case in which the number of comparisons is highest. What is that?
</p>
<p>
Our algorithm applies in general to any array. The running time depends on the first position where $42$ is present.
In the <em>worst case</em>, $42$ is either not present in the array or present only at the last position and hence
the <em>worst case</em>running time is $f(n) = O(n).
	</p>
<p class = "question">How should the array be for $f(n)$ to be minimum?</p>
<p>When we talk about the running time of an algorithm, we always talk about the worst case running time.</p>
<p>We also consider at times, the average case running time. Here if the $42$ is present right at the middle of the
array, the running time is $f(n) = O(\frac{n}{2})$ and this is said to be the <em>average case running time</em>.
<p>Many algorithms give their <u>worst-case</u> performance in terms of big-O.</p>
<p>Other measures include <u>average-case</u> or <u>best-case</u> analysis.</p>
<p>Example: Sequential Search on n elements</p>
<p>Worst Case: $O(n)$</p>
<p>Average Case: $O(\frac{n}{2}) = O(n)$</p>
<p>Best Case: $O(1)$</p>
<p class="question">
You are given an array of $n$ numbers. The array has both positive and negative numbers. Your algorithm has to return
the index of the first negative number. What is the arrangement of the array that will cause the worst running time?
What is the average case and its running time?
</p>
<h4>Growth of Functions</h4>
<center>
	<img src="img/n.JPG" width="50%" height="50%" align="center"></img><br/><br/>
	Graph of $f(n) = O(n)$<br/><br/>
</center>

<center>
	<img src="img/n_square.JPG" width="50%" height="50%" align="center"></img><br/><br/>
	Graph of $f(n) = O(n^2)$<br/><br/>
</center>

<center>
	<img src="img/logn.JPG" width="50%" height="50%" align="center"></img><br/><br/>
	Graph of $f(n) = O(\log n)$<br/><br/>
</center>

<center>
	<img src="img/powerof2.jpg" width="100%" height="100%" align="center"></img><br/><br/>
	Graph of $f(n) = O(2^n), g(n) = O(n^4)$<br/><br/>
</center>
<p align="CENTER">One more example</p>
<p>Consider an algorithm that processes n data items in one minute. How long
will it take to process 32 times as many items on the same computer using the
same algorithm?</p>
<pre>Worst Case Complexity APPROX TIME</pre>
<pre>O(n)                   32 min</pre>
<pre>O(n<sup>2</sup>)                  ~17 hr</pre>
<pre>O(2<sup>n</sup>)                  2^31n minutes = YOU&#8217;RE DEAD</pre>
<p align="CENTER">Another view</p>
<p>What is the maximum number of inputs that can be processed by an algorithm in
one hour if one operation takes 1 microsecond?</p>
<pre>Number of Ops              Max. Problem Size</pre>
</font><blockquote><font color="#000000" face="Arial" size="5">
</font><font color="#000000" face="Arial" size="4">
<pre>400n = O(n)               9,000,000</pre>
<pre>2n<sup>2</sup> = O(n<sup>2</sup>)                42,426</pre>
<pre>2<sup>n</sup> = O(2<sup>n</sup>)                 31</pre>
</font></blockquote><font color="#000000" face="Arial" size="4">
</font></blockquote><font color="#000000" face="Arial" size="4">
</font><font color="#000000" face="Arial" size="6">
<p align="CENTER">What if we had a faster CPU?</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="5">
<p>What if the CPU were 256 times faster?<br>
(m = original maximum problem size)</p>
<pre>Number of Ops               New Max. Problem Size</pre>
</font><blockquote><font color="#000000" face="Arial" size="5">
</font><font color="#000000" face="Arial" size="4">
<pre>400n                        256m</pre>
<pre>2n<sup>2</sup> = O(n<sup>2</sup>)                  16m</pre>
<pre>2<sup>n</sup> = O(2<sup>n</sup>)                   m+8</pre>
</font></blockquote><font color="#000000" face="Arial" size="4">
</font></blockquote><font color="#000000" face="Arial" size="4">
</font><font color="#000000" face="Arial" size="6">
<!-- To go  -->
<p align="CENTER">Misuse of the Big O!</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="5">
<p>Number of Operations: 10<sup>10</sup>n</p>
<p>Is this O(n)?</p>
<p>(probably not)</p>
<p>What is considered an efficient measure for an algorithm?</p>
<p>Yes: O(log n), O(n), O(n log n),even O(n<sup>2</sup>) sometimes</p>
<p>No: O(n<sup>100</sup>), O(2<sup>n</sup>)</p>
</font></blockquote><font color="#000000" face="Arial" size="5">
</font><font color="#000000" face="Arial" size="6">
<!-- End of To go  -->
<p align="CENTER">Tale of Two Algorithms</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="4">
<p>Given an array X storing n numbers, we want to compute an array A such that
A[i] is the average of elements X[0],&#8230;,X[i], for i=0,&#8230;,n-1.</p>
<p>Calculating "prefix averages"</p>
<p>Used in economics: Given year-by-year returns on a mutual fund, an investor
will want to know the average return over the past 3 years, 5 years, 10 years,
etc.</p>
</font></blockquote><font color="#000000" face="Arial" size="4">
</font><font color="#000000" face="Arial" size="6">
<p align="CENTER">First Attempt</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="4">
<p>prefixAverages1(X)</p>
<blockquote>
  <p>Let A[ ] be an array of n numbers</p>
  <p>for i = 0 to n-1 do</p>
  <blockquote>
    <p>sum = 0</p>
    <p>for j = 0 to i do</p>
    <blockquote>
      <p>sum = sum + X[ j ]</p>
    </blockquote>
    <p>A[ i ] = sum/(i + 1)</p>
  </blockquote>
  <p>return array A</p>
</blockquote>
<p>Order of Complexity?</p>
<p>O(n<sup>2</sup>)</p>
</font></blockquote><font color="#000000" face="Arial" size="4">
</font><font color="#000000" face="Arial" size="6">
<p align="CENTER">An Observation</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="5">
<p>In the original algorithm, a lot of computations are recomputed over and over
again.</p>
<p>A[i-1] = (X[0] + X[1] + &#8230; + X[i-1]) / i</p>
<p>A[i] = (X[0] + X[1] + &#8230; + X[i-1] + X[i]) / (i+1)</p>
<p>Let the prefix sum<br>
S<sub>i</sub> = X[0] + X[1] + &#8230; + X[i-1] + X[i]</p>
<p>A[i-1] = (S<sub>i-1</sub>) / i</p>
<p>A[i] = (S<sub>i-1</sub> + X[i])/ (i+1)</p>
</font></blockquote><font color="#000000" face="Arial" size="5">
</font><font color="#000000" face="Arial" size="6">
<p align="CENTER">Second Attempt</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="4">
<p>prefixAverages2(X)</p>
<blockquote>
  <p>Let A[ ] be an array of n numbers</p>
  <p>sum = 0</p>
  <p>for i = 0 to n-1 do</p>
  <blockquote>
    <p>sum = sum + X[ i ]</p>
    <p>A[ i ] = sum/(i + 1)</p>
  </blockquote>
  <p>return array A</p>
</blockquote>
<p>Order of Complexity?</p>
<p>O(n)</p>
</font></blockquote><font color="#000000" face="Arial" size="4">
</font><font color="#000000" face="Arial" size="6">
<p align="CENTER">Competing Algorithms</p>
</font><blockquote><font color="#000000" face="Arial" size="6">
</font><font color="#000000" face="Arial" size="5">
<p>Algorithm A: O(n log n)</p>
<p>Algorithm B: O(n<sup>2</sup>)</p>
<p>Which is more efficient?</p>
<p><img src="unit1_files/unit1.gif" border="0" height="152" width="378"></p>
</font></blockquote><font color="#000000" face="Arial" size="5">
</font><p>&nbsp;</p>

<p>&nbsp;</p>

<hr>

<p align="center"><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/courseinfo.htm"><strong><font color="#800000" face="Arial">Course
Info</font></strong></a><font color="#800000" face="Arial"><strong> | </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/schedule.htm"><strong>Schedule</strong></a><strong>
| </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/sections.htm"><strong>Sections</strong></a><strong>
| <a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/announcements.htm">Announcements</a> | </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/homework.htm"><strong>Homework</strong></a><strong>
| </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/exams.htm"><strong>Exams</strong></a><strong>
| </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/help.htm"><strong>Help/FAQ</strong></a><strong>
| </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/grades.htm"><strong>Grades</strong></a><strong>
| </strong><a href="http://www.cs.sunysb.edu/%7Ecse214/lecture_slides/index.html"><strong>HOME</strong></a></font></p>


</body></html>
